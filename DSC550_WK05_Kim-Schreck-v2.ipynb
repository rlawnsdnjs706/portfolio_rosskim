{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfd24b84-6616-4213-9622-331a533e939a",
   "metadata": {},
   "source": [
    "# DSC550_WK05.2_Kim-Schreck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "005d2ede-65d4-4c70-b4df-22af2f0d92e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/gimjun-\n",
      "[nltk_data]     won/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6599cce0-bdde-4305-a735-775a431ef910",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5f80fa9-88be-44ed-afdb-8d228bc6fb90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5.2.01 \n",
    "# convert tsv 01 to csv\n",
    "\n",
    "with open('labeledTrainData.tsv', 'r') as tsvfile:\n",
    "    reader = csv.reader(tsvfile, delimiter='\\t')\n",
    "    with open('labeledTrainData.csv', 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for row in reader:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa841abf-846c-4782-bdaa-2e400327df23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5.2.01 \n",
    "# convert tsv 02 to csv\n",
    "\n",
    "with open('testData.tsv', 'r') as tsvfile:\n",
    "    reader = csv.reader(tsvfile, delimiter='\\t')\n",
    "    with open('testData.csv', 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for row in reader:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41a6480e-8cd0-4999-b93f-5badf1968633",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id  sentiment                                             review\n",
      "0  5814_8          1  With all this stuff going down at the moment w...\n",
      "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
      "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
      "3  3630_4          0  It must be assumed that those who praised this...\n",
      "4  9495_8          1  Superbly trashy and wondrously unpretentious 8...\n"
     ]
    }
   ],
   "source": [
    "# 5.2.01\n",
    "# read dt01\n",
    "\n",
    "dt01 = pd.read_csv('labeledTrainData.csv')\n",
    "print(dt01.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb009bb4-5eb5-413f-ad84-96e5c90e8096",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id                                             review\n",
      "0  12311_10  Naturally in a film who's main themes are of m...\n",
      "1    8348_2  This movie is a disaster within a disaster fil...\n",
      "2    5828_4  All in all, this is a movie for kids. We saw i...\n",
      "3    7186_2  Afraid of the Dark left me with the impression...\n",
      "4   12128_7  A very accurate depiction of small time mob li...\n"
     ]
    }
   ],
   "source": [
    "# 5.2.01\n",
    "# read dt02\n",
    "\n",
    "dt02 = pd.read_csv('testData.csv')\n",
    "print(dt02.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e19be680-ea3c-45b3-b0b7-1aaa12e36208",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "sentiment\n",
      "review\n"
     ]
    }
   ],
   "source": [
    "# 5.2.01\n",
    "# show columns\n",
    "\n",
    "for col in dt01.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c724d71c-1b84-4abf-a2ec-2ef62319edb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "review\n"
     ]
    }
   ],
   "source": [
    "# 5.2.01\n",
    "# show columns\n",
    "\n",
    "for col in dt02.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1da1b7cf-e740-4038-9c81-781670266a38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5.2.01\n",
    "# assign variables\n",
    "\n",
    "dt01_trn = dt01\n",
    "dt02_tst = dt02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce984338-73fa-4037-9b8d-3c2204bda22e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5.2.02\n",
    "# split training and testing data\n",
    "\n",
    "trn_x1 = dt01_trn['review']\n",
    "trn_y1 = dt01_trn['review']\n",
    "tst_x1 = dt02_tst['review']\n",
    "tst_y1 = dt02_tst['review']\n",
    "trn_x2=[]\n",
    "tst_x2=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d365a59-4a4e-41c6-b19f-b34664bea6fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data\n",
      "0        With all this stuff going down at the moment w...\n",
      "1        \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
      "2        The film starts with a manager (Nicholas Bell)...\n",
      "3        It must be assumed that those who praised this...\n",
      "4        Superbly trashy and wondrously unpretentious 8...\n",
      "                               ...                        \n",
      "24995    It seems like more consideration has gone into...\n",
      "24996    I don't believe they made this film. Completel...\n",
      "24997    Guy is a loser. Can't get girls, needs to buil...\n",
      "24998    This 30 minute documentary Bu√±uel made in the ...\n",
      "24999    I saw this movie as a child and it broke my he...\n",
      "Name: review, Length: 25000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 5.2.02\n",
    "# return training data\n",
    "\n",
    "print(\"training data\")\n",
    "print(trn_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4a9c062-6d4c-4822-be13-c712e31eb2b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing data\n",
      "0        Naturally in a film who's main themes are of m...\n",
      "1        This movie is a disaster within a disaster fil...\n",
      "2        All in all, this is a movie for kids. We saw i...\n",
      "3        Afraid of the Dark left me with the impression...\n",
      "4        A very accurate depiction of small time mob li...\n",
      "                               ...                        \n",
      "24995    Sony Pictures Classics, I'm looking at you! So...\n",
      "24996    I always felt that Ms. Merkerson had never got...\n",
      "24997    I was so disappointed in this movie. I am very...\n",
      "24998    From the opening sequence, filled with black a...\n",
      "24999    This is a great horror film for people who don...\n",
      "Name: review, Length: 25000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 5.2.02\n",
    "# return testing data\n",
    "\n",
    "print(\"testing data\")\n",
    "print(tst_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e1f00b1-55d7-40ca-930a-c5bd0cf532b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 73342)\t4\n",
      "  (0, 2662)\t4\n",
      "  (0, 66562)\t11\n",
      "  (0, 63783)\t1\n",
      "  (0, 27963)\t3\n",
      "  (0, 19854)\t1\n",
      "  (0, 4753)\t2\n",
      "  (0, 66339)\t19\n",
      "  (0, 43526)\t1\n",
      "  (0, 43300)\t11\n",
      "  (0, 70920)\t2\n",
      "  (0, 62903)\t1\n",
      "  (0, 38991)\t1\n",
      "  (0, 67125)\t9\n",
      "  (0, 31095)\t3\n",
      "  (0, 44529)\t2\n",
      "  (0, 72259)\t1\n",
      "  (0, 46634)\t1\n",
      "  (0, 19380)\t1\n",
      "  (0, 30670)\t1\n",
      "  (0, 3258)\t10\n",
      "  (0, 66432)\t1\n",
      "  (0, 72253)\t2\n",
      "  (0, 73394)\t1\n",
      "  (0, 43761)\t2\n",
      "  :\t:\n",
      "  (24999, 12040)\t3\n",
      "  (24999, 70505)\t1\n",
      "  (24999, 57728)\t1\n",
      "  (24999, 9237)\t1\n",
      "  (24999, 67281)\t1\n",
      "  (24999, 15841)\t1\n",
      "  (24999, 41828)\t1\n",
      "  (24999, 36574)\t1\n",
      "  (24999, 2155)\t1\n",
      "  (24999, 28637)\t1\n",
      "  (24999, 65531)\t1\n",
      "  (24999, 3430)\t1\n",
      "  (24999, 69585)\t1\n",
      "  (24999, 12161)\t1\n",
      "  (24999, 24013)\t1\n",
      "  (24999, 9234)\t1\n",
      "  (24999, 17690)\t1\n",
      "  (24999, 15790)\t1\n",
      "  (24999, 17237)\t1\n",
      "  (24999, 37566)\t1\n",
      "  (24999, 61619)\t1\n",
      "  (24999, 69467)\t1\n",
      "  (24999, 34277)\t1\n",
      "  (24999, 12117)\t2\n",
      "  (24999, 69561)\t1\n"
     ]
    }
   ],
   "source": [
    "# 5.2.03\n",
    "# return count\n",
    "\n",
    "cnt = CountVectorizer()\n",
    "cnt_wrd=cnt.fit_transform(trn_x1)\n",
    "print(cnt_wrd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f28f387-9164-482a-91a5-e3d070d700ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 74849)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.2.03\n",
    "# return dimensions of training set\n",
    "\n",
    "cnt_wrd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efde1d98-b754-414c-8233-3aed5bc58eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# 5.2.03\n",
    "# transform training set to array\n",
    "\n",
    "print(cnt_wrd.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc7f3e4c-5f0e-4810-bec2-a2bfd0a4fa96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5.2.03\n",
    "# apply and fit tf_idf vectorization to training set\n",
    "\n",
    "tf_idf = TfidfVectorizer()\n",
    "trn_x1_tf = tf_idf.fit_transform(trn_x1)\n",
    "trn_x1_tf = tf_idf.transform(trn_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3492caac-514a-4e75-a6ad-ba02cf15b3fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 25000, n_features: 74849\n"
     ]
    }
   ],
   "source": [
    "# 5.2.03\n",
    "# return tf_idf vectorization of training set\n",
    "\n",
    "print(\"n_samples: %d, n_features: %d\" % trn_x1_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "192800b9-550d-4897-af1c-d413d1ad2994",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5.2.03\n",
    "# apply tf_idf vectorization to test set\n",
    "\n",
    "tst_x1_tf = tf_idf.transform(tst_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4d3a5fe-fb39-4524-90b6-bf91cc7cb208",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 25000, n_features: 74849\n"
     ]
    }
   ],
   "source": [
    "# 5.2.03\n",
    "# return tf_idf vectorization of test set\n",
    "\n",
    "print(\"n_samples: %d, n_features: %d\" % tst_x1_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10cbd331-e081-4123-801a-8140e3f61186",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5.2.05\n",
    "# train logisitc regression\n",
    "\n",
    "stpwrd = nltk.corpus.stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93a977c3-b147-4fd6-90f3-6ddd8af85c25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5.2.05\n",
    "# train logistic regression\n",
    "\n",
    "for i in range(0, len(trn_x1)):\n",
    "    rvw = re.sub('[^a-zA-Z]', ' ', trn_x1[i])\n",
    "    rvw = rvw.lower()\n",
    "    rvw = rvw.split()\n",
    "    rvw = [lemmatizer.lemmatize(word) for word in rvw if not word in set(stpwrd)]\n",
    "    rvw = ' '.join(rvw)\n",
    "    trn_x2.append(rvw)\n",
    "\n",
    "for i in range(0, len(tst_x1)):\n",
    "    rvw = re.sub('[^a-zA-Z]', ' ', tst_x1[i])\n",
    "    rvw = rvw.lower()\n",
    "    rvw = rvw.split()\n",
    "    rvw = [lemmatizer.lemmatize(word) for word in rvw if not word in set(stpwrd)]\n",
    "    rvw = ' '.join(rvw)\n",
    "    tst_x2.append(rvw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44cdfd26-eac8-4018-b3d3-2484e484c66b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happens army wetback towelheads godless eastern european commie gather force south border gary busey kick butt course another laughable example reagan era cultural fallout bulletproof waste decent supporting cast headed l q jones thalmus rasulala'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.2.05\n",
    "# return trained logistic regression\n",
    "\n",
    "trn_x2[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb34b035-dc31-4920-a947-a46981017709",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MultinomialNB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 5.2.05\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# apply classifier\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# freezes on this step\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# unable to proceed\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m nv_bys_class \u001b[38;5;241m=\u001b[39m MultinomialNB()\n\u001b[1;32m      7\u001b[0m nv_bys_class\u001b[38;5;241m.\u001b[39mfit(trn_x1_tf, trn_y1)\n\u001b[1;32m      8\u001b[0m pred_y \u001b[38;5;241m=\u001b[39m nv_bys_class\u001b[38;5;241m.\u001b[39mpredict(tst_x1_tf)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MultinomialNB' is not defined"
     ]
    }
   ],
   "source": [
    "# 5.2.05\n",
    "# apply classifier\n",
    "# freezes on this step\n",
    "# unable to proceed\n",
    "\n",
    "nv_bys_class = MultinomialNB()\n",
    "nv_bys_class.fit(trn_x1_tf, trn_y1)\n",
    "pred_y = nv_bys_class.predict(tst_x1_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "252cbb0a-ab84-4d9e-9be9-0c245bb79a06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tst_y2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 5.2.06\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# return accuracy\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# unable to proceed\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics\u001b[38;5;241m.\u001b[39mclassification_report(tst_y2, pred_y, target_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tst_y2' is not defined"
     ]
    }
   ],
   "source": [
    "# 5.2.06\n",
    "# return accuracy\n",
    "# unable to proceed\n",
    "\n",
    "print(metrics.classification_report(tst_y2, pred_y, target_names=['positive', 'negative']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5655cdc-7377-46b4-88e2-a8af677a43f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tst_y2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 5.2.07\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# return confusion matrix\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# unable to proceed\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfusion matrix:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics\u001b[38;5;241m.\u001b[39mconfusion_matrix(tst_y2, pred_y))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tst_y2' is not defined"
     ]
    }
   ],
   "source": [
    "# 5.2.07\n",
    "# return confusion matrix\n",
    "# unable to proceed\n",
    "\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(tst_y2, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3ebe27c-9fbf-4f83-9ef8-fc7524c0777f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [25000, 0]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 5.2.05\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# train logisitc regression\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# unable to proceed\u001b[39;00m\n\u001b[1;32m      5\u001b[0m logr \u001b[38;5;241m=\u001b[39m linear_model\u001b[38;5;241m.\u001b[39mLogisticRegression()\n\u001b[0;32m----> 6\u001b[0m logr\u001b[38;5;241m.\u001b[39mfit(trn_x1_tf,trn_x2)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1349\u001b[0m     )\n\u001b[1;32m   1350\u001b[0m ):\n\u001b[0;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1201\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1199\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m-> 1201\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m   1202\u001b[0m     X,\n\u001b[1;32m   1203\u001b[0m     y,\n\u001b[1;32m   1204\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1205\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m_dtype,\n\u001b[1;32m   1206\u001b[0m     order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1207\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39msolver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1208\u001b[0m )\n\u001b[1;32m   1209\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1210\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1192\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1193\u001b[0m     X,\n\u001b[1;32m   1194\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1206\u001b[0m )\n\u001b[1;32m   1208\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m-> 1210\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:430\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    428\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 430\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    431\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    432\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    433\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [25000, 0]"
     ]
    }
   ],
   "source": [
    "# 5.2.05\n",
    "# train logisitc regression\n",
    "# unable to proceed\n",
    "\n",
    "logr = linear_model.LogisticRegression()\n",
    "logr.fit(trn_x1_tf,trn_x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4f90054-706b-4584-9a7f-f794115a284e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 5.2.05\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# return predicted\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# unable to proceed\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m predicted \u001b[38;5;241m=\u001b[39m logr\u001b[38;5;241m.\u001b[39mpredict(numpy\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m3.46\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'numpy' is not defined"
     ]
    }
   ],
   "source": [
    "# 5.2.05\n",
    "# return predicted\n",
    "# unable to proceed\n",
    "\n",
    "predicted = logr.predict(numpy.array([3.46]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5707a42-12bb-4b42-9d4a-bc67461229eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5.2.08\n",
    "# func f1 score\n",
    "# unable to proceed\n",
    "\n",
    "def f1_sc(pc, rc):\n",
    "    return 2*((pc*rc)/(pc+rc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc3eeaac-cd9c-49be-9c64-325c0d7f45d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'arrange'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 5.2.08\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# get precision\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# unable to proceed\u001b[39;00m\n\u001b[1;32m      5\u001b[0m precision \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marrange(pred_y):\n\u001b[1;32m      8\u001b[0m     precision\u001b[38;5;241m.\u001b[39mappend(i)\n\u001b[1;32m      9\u001b[0m precision\u001b[38;5;241m.\u001b[39mappend(pred_y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/__init__.py:328\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemoved in NumPy 1.25.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTester was removed in NumPy 1.25.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 328\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    329\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'arrange'"
     ]
    }
   ],
   "source": [
    "# 5.2.08\n",
    "# get precision\n",
    "# unable to proceed\n",
    "\n",
    "precision = []\n",
    "\n",
    "for i in np.arrange(pred_y):\n",
    "    precision.append(i)\n",
    "precision.append(pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cbae725c-9f1f-4e10-bd3a-c7e8e0e6ffc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'arrange'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 5.2.08\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# get recall\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# unable to proceed\u001b[39;00m\n\u001b[1;32m      5\u001b[0m recall \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marrange(pred_y):\n\u001b[1;32m      8\u001b[0m     recall\u001b[38;5;241m.\u001b[39mappend(i)\n\u001b[1;32m      9\u001b[0m recall\u001b[38;5;241m.\u001b[39mappend(pred_y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/__init__.py:328\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemoved in NumPy 1.25.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTester was removed in NumPy 1.25.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 328\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    329\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'arrange'"
     ]
    }
   ],
   "source": [
    "# 5.2.08\n",
    "# get recall\n",
    "# unable to proceed\n",
    "\n",
    "recall = []\n",
    "\n",
    "for i in np.arrange(pred_y):\n",
    "    recall.append(i)\n",
    "recall.append(pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c54253d2-d4bf-4882-9401-205def385c8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5.2.08\n",
    "# get f1 score\n",
    "# unable to proceed\n",
    "\n",
    "f1_score = []\n",
    "\n",
    "for pr in zip (precision, recall):\n",
    "    f1_score.append(f1_sc(pc, rc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ede0705-a3ea-41b0-8bfe-66e9a0d65718",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'log_regression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 5.2.09\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# define metrics\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# unable to proceed\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m pred_y_prob \u001b[38;5;241m=\u001b[39m log_regression\u001b[38;5;241m.\u001b[39mpredict_proba(tst_x1_tf)[::,\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      6\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mroc_curve(tst_y1, pred_y_prob)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'log_regression' is not defined"
     ]
    }
   ],
   "source": [
    "# 5.2.09\n",
    "# define metrics\n",
    "# unable to proceed\n",
    "\n",
    "pred_y_prob = log_regression.predict_proba(tst_x1_tf)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(tst_y1, pred_y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b41c32ca-8805-4efb-8a6a-c14fc426a6b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fpr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 5.2.09\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# create a ROC curve\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# unable to proceed\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(fpr,tpr)\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue Positive Rate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFalse Positive Rate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fpr' is not defined"
     ]
    }
   ],
   "source": [
    "# 5.2.09\n",
    "# create a ROC curve\n",
    "# unable to proceed\n",
    "\n",
    "plt.plot(fpr,tpr)\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6cee5d4c-baff-4af8-b964-b4fa27a33579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3161 3064]\n",
      " [3114 3161]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.51      0.51      6225\n",
      "           1       0.51      0.50      0.51      6275\n",
      "\n",
      "    accuracy                           0.51     12500\n",
      "   macro avg       0.51      0.51      0.51     12500\n",
      "weighted avg       0.51      0.51      0.51     12500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5.2.10\n",
    "# KNN classifier\n",
    "\n",
    "# assign values to x and y variables:\n",
    "x3 = dt01.iloc[:, :-1].values\n",
    "y3 = dt01.iloc[:, 1].values\n",
    "\n",
    "# split into random train and test subsets:\n",
    "trn_x3, tst_x3, trn_y3, tst_y3 = train_test_split(x3, y3, test_size=0.50) \n",
    "\n",
    "# standardize features by removing mean and scaling to unit variance:\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(trn_x3)\n",
    "trn_x3 = scaler.transform(trn_x3)\n",
    "tst_x3 = scaler.transform(tst_x3) \n",
    "\n",
    "# sse KNN classifier to fit data:\n",
    "clssfr = KNeighborsClassifier(n_neighbors=5)\n",
    "clssfr.fit(trn_x3, trn_y3)\n",
    "\n",
    "# predict y data with classifier:\n",
    "pred_y3 = clssfr.predict(trn_x3)\n",
    "\n",
    "# return results:\n",
    "print(confusion_matrix(tst_y3, pred_y3))\n",
    "print(classification_report(tst_y3, pred_y3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bc88fd-0dbc-4b26-84fd-48d9fe57c083",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
